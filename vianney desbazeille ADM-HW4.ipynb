{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc7403ca",
   "metadata": {},
   "source": [
    "# Homework 4 - Recommendation systems and clustering everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3100310a",
   "metadata": {},
   "source": [
    "This work as been done by : Vianney Desbazeille, mailing adress : vianney.desbazeille@eleve.isep.fr.\n",
    "Do not hesitate to reach me if you have any questions about my work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c63c8c",
   "metadata": {},
   "source": [
    "## 1. Recommendation sytem\n",
    "\n",
    "### 1.2 Minhash Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa62832f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0             datetime  duration  \\\n",
      "0            58773  2017-01-01 01:15:09       0.0   \n",
      "1            58774  2017-01-01 13:56:02       0.0   \n",
      "2            58775  2017-01-01 15:17:47   10530.0   \n",
      "3            58776  2017-01-01 16:04:13      49.0   \n",
      "4            58777  2017-01-01 19:16:37       0.0   \n",
      "...            ...                  ...       ...   \n",
      "671731      730504  2019-06-30 21:37:08     851.0   \n",
      "671732      730505  2019-06-30 21:49:34   91157.0   \n",
      "671733      730506  2019-06-30 22:00:44       0.0   \n",
      "671734      730507  2019-06-30 22:04:23       0.0   \n",
      "671735      730508  2019-06-30 22:35:24       0.0   \n",
      "\n",
      "                                            title  \\\n",
      "0              Angus, Thongs and Perfect Snogging   \n",
      "1                    The Curse of Sleeping Beauty   \n",
      "2                               London Has Fallen   \n",
      "3                                        Vendetta   \n",
      "4                 The SpongeBob SquarePants Movie   \n",
      "...                                           ...   \n",
      "671731        Oprah Presents When They See Us Now   \n",
      "671732                               HALO Legends   \n",
      "671733                                Pacific Rim   \n",
      "671734  ReMastered: The Two Killings of Sam Cooke   \n",
      "671735                                 Chopsticks   \n",
      "\n",
      "                                                   genres release_date  \\\n",
      "0                                  Comedy, Drama, Romance   2008-07-25   \n",
      "1                      Fantasy, Horror, Mystery, Thriller   2016-06-02   \n",
      "2                                        Action, Thriller   2016-03-04   \n",
      "3                                           Action, Drama   2015-06-12   \n",
      "4       Animation, Action, Adventure, Comedy, Family, ...   2004-11-19   \n",
      "...                                                   ...          ...   \n",
      "671731                                          Talk-Show   2019-06-12   \n",
      "671732       Animation, Action, Adventure, Family, Sci-Fi   2010-02-16   \n",
      "671733                          Action, Adventure, Sci-Fi   2013-07-12   \n",
      "671734                                 Documentary, Music   2019-02-08   \n",
      "671735                                      Comedy, Drama   2019-05-31   \n",
      "\n",
      "          movie_id     user_id  \n",
      "0       26bd5987e8  1dea19f6fe  \n",
      "1       f26ed2675e  544dcbc510  \n",
      "2       f77e500e7a  7cbcc791bf  \n",
      "3       c74aec7673  ebf43c36b6  \n",
      "4       a80d6fc2aa  a57c992287  \n",
      "...            ...         ...  \n",
      "671731  43cd23f30f  57501964fd  \n",
      "671732  febf42d55f  d4fcb079ba  \n",
      "671733  7b15e5ada1  4a14a2cd5a  \n",
      "671734  52d49c515a  0b8163ea4b  \n",
      "671735  0be62aac8b  5e5755d816  \n",
      "\n",
      "[671736 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import pandas as pd\n",
    "\n",
    "def minhash_signature(set_elements, num_perm):\n",
    "    # Step 1: Set Parameters\n",
    "    hash_functions = [hashlib.sha256(str(i).encode()).hexdigest() for i in range(num_perm)]\n",
    "    minhash_sig = [float('inf')] * num_perm  # Step 3: Initialize MinHash Signature\n",
    "\n",
    "    # Step 4: Update Signature\n",
    "    for element in set_elements:\n",
    "        for i, hash_function in enumerate(hash_functions):\n",
    "            hash_val = int(hashlib.sha256((str(element) + hash_function).encode()).hexdigest(), 16)\n",
    "            minhash_sig[i] = min(minhash_sig[i], hash_val)\n",
    "\n",
    "    # Step 5: Final Signature\n",
    "    return minhash_sig\n",
    "\n",
    "# Importing data \n",
    "csv_file_path = 'vodclickstream_uk_movies_03.csv'  \n",
    "data = pd.read_csv(csv_file_path)\n",
    "print(data)\n",
    "# Number of hash functions for MinHash\n",
    "num_perm = 128\n",
    "\n",
    "# Create MinHash signatures for each user\n",
    "minhashes = {}\n",
    "for index, row in data.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    genres = row['genres'].split(',')  # Assuming genres are stored as a comma-separated string\n",
    "\n",
    "    minhash = minhash_signature(genres, num_perm)\n",
    "    minhashes[user_id] = minhash\n",
    "\n",
    "# Simple function to calculate Jaccard similarity between two sets\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set(set1) & set(set2))\n",
    "    union = len(set(set1) | set(set2))\n",
    "    return intersection / union if union != 0 else 0.0\n",
    "\n",
    "# Threshold for similarity\n",
    "threshold = 0.6\n",
    "\n",
    "# Group users with similar interests into buckets\n",
    "buckets = {}\n",
    "for user_id, minhash in minhashes.items():\n",
    "    similar_users = [other_user for other_user, other_minhash in minhashes.items()\n",
    "                     if jaccard_similarity(minhash, other_minhash) >= threshold]\n",
    "    buckets[user_id] = similar_users\n",
    "    print(buckets)\n",
    "\n",
    "# Display the buckets\n",
    "for user_id, similar_users in buckets.items():\n",
    "    print(f\"User {user_id} is in a bucket with similar users: {similar_users}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd20cff8",
   "metadata": {},
   "source": [
    "### 1.3 Locality-Sensitive Hashing (LSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "702aa4b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0             datetime  duration  \\\n",
      "0            58773  2017-01-01 01:15:09       0.0   \n",
      "1            58774  2017-01-01 13:56:02       0.0   \n",
      "2            58775  2017-01-01 15:17:47   10530.0   \n",
      "3            58776  2017-01-01 16:04:13      49.0   \n",
      "4            58777  2017-01-01 19:16:37       0.0   \n",
      "...            ...                  ...       ...   \n",
      "671731      730504  2019-06-30 21:37:08     851.0   \n",
      "671732      730505  2019-06-30 21:49:34   91157.0   \n",
      "671733      730506  2019-06-30 22:00:44       0.0   \n",
      "671734      730507  2019-06-30 22:04:23       0.0   \n",
      "671735      730508  2019-06-30 22:35:24       0.0   \n",
      "\n",
      "                                            title  \\\n",
      "0              Angus, Thongs and Perfect Snogging   \n",
      "1                    The Curse of Sleeping Beauty   \n",
      "2                               London Has Fallen   \n",
      "3                                        Vendetta   \n",
      "4                 The SpongeBob SquarePants Movie   \n",
      "...                                           ...   \n",
      "671731        Oprah Presents When They See Us Now   \n",
      "671732                               HALO Legends   \n",
      "671733                                Pacific Rim   \n",
      "671734  ReMastered: The Two Killings of Sam Cooke   \n",
      "671735                                 Chopsticks   \n",
      "\n",
      "                                                   genres release_date  \\\n",
      "0                                  Comedy, Drama, Romance   2008-07-25   \n",
      "1                      Fantasy, Horror, Mystery, Thriller   2016-06-02   \n",
      "2                                        Action, Thriller   2016-03-04   \n",
      "3                                           Action, Drama   2015-06-12   \n",
      "4       Animation, Action, Adventure, Comedy, Family, ...   2004-11-19   \n",
      "...                                                   ...          ...   \n",
      "671731                                          Talk-Show   2019-06-12   \n",
      "671732       Animation, Action, Adventure, Family, Sci-Fi   2010-02-16   \n",
      "671733                          Action, Adventure, Sci-Fi   2013-07-12   \n",
      "671734                                 Documentary, Music   2019-02-08   \n",
      "671735                                      Comedy, Drama   2019-05-31   \n",
      "\n",
      "          movie_id     user_id  clicks  \n",
      "0       26bd5987e8  1dea19f6fe     840  \n",
      "1       f26ed2675e  544dcbc510      75  \n",
      "2       f77e500e7a  7cbcc791bf    1084  \n",
      "3       c74aec7673  ebf43c36b6      11  \n",
      "4       a80d6fc2aa  a57c992287     637  \n",
      "...            ...         ...     ...  \n",
      "671731  43cd23f30f  57501964fd      77  \n",
      "671732  febf42d55f  d4fcb079ba     183  \n",
      "671733  7b15e5ada1  4a14a2cd5a     355  \n",
      "671734  52d49c515a  0b8163ea4b     104  \n",
      "671735  0be62aac8b  5e5755d816      60  \n",
      "\n",
      "[671736 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from CSV file\n",
    "csv_file_path = 'vodclickstream_uk_movies_03.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "title_counts = data['title'].value_counts()\n",
    "\n",
    "# Add a new column based on the key-value mapping\n",
    "data['clicks'] = data['title'].map(title_counts)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_csv_path = 'vodclickstream_uk_movies_03_2.csv'  \n",
    "data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "data = pd.read_csv(output_csv_path)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2acfffe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies for User 1dea19f6fe: ['f33856f257', 'eb91c694cc', 'e0203fcd07', '254b5432f4', '2d01b1371c']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "# Function to create MinHash signature\n",
    "def minhash_signature(set_elements, num_perm):\n",
    "    hash_functions = [hashlib.sha256(str(i).encode()).hexdigest() for i in range(num_perm)]\n",
    "    minhash_sig = [float('inf')] * num_perm\n",
    "\n",
    "    for element in set_elements:\n",
    "        for i, hash_function in enumerate(hash_functions):\n",
    "            hash_val = int(hashlib.sha256((str(element) + hash_function).encode()).hexdigest(), 16)\n",
    "            minhash_sig[i] = min(minhash_sig[i], hash_val)\n",
    "\n",
    "    return minhash_sig\n",
    "\n",
    "# Function to calculate Jaccard similarity\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set(set1) & set(set2))\n",
    "    union = len(set(set1) | set(set2))\n",
    "    return intersection / union if union != 0 else 0.0\n",
    "\n",
    "# Read data from CSV file\n",
    "csv_file_path = 'vodclickstream_uk_movies_03_2.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Number of hash functions for MinHash\n",
    "num_perm = 128\n",
    "\n",
    "# Create MinHash signatures for each user\n",
    "minhashes = {}\n",
    "for index, row in data.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    genres = row['genres'].split(',')  # Assuming genres are stored as a comma-separated string\n",
    "\n",
    "    minhash = minhash_signature(genres, num_perm)\n",
    "    minhashes[user_id] = minhash\n",
    "\n",
    "# Function to find similar users based on MinHash similarity\n",
    "def find_similar_users(query_user_id, minhashes, threshold=0.6):\n",
    "    query_minhash = minhashes[query_user_id]\n",
    "    similar_users = [(other_user, jaccard_similarity(query_minhash, other_minhash))\n",
    "                     for other_user, other_minhash in minhashes.items()\n",
    "                     if other_user != query_user_id and jaccard_similarity(query_minhash, other_minhash) >= threshold]\n",
    "\n",
    "    # Sort by similarity in descending order\n",
    "    similar_users.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return similar_users[:2]  # Return the two most similar users\n",
    "\n",
    "# Function to recommend movies to a user\n",
    "def recommend_movies(user_id, minhashes, data):\n",
    "    similar_users = find_similar_users(user_id, minhashes)\n",
    "    \n",
    "    recommended_movies = []\n",
    "    \n",
    "    # Check common movies between the two most similar users\n",
    "    common_movies = set(data[data['user_id'] == similar_users[0][0]]['movie_id']).intersection(\n",
    "                    set(data[data['user_id'] == similar_users[1][0]]['movie_id']))\n",
    "    \n",
    "    if common_movies:\n",
    "        # Sort common movies based on the total number of clicks by similar users\n",
    "        common_movies = sorted(common_movies, key=lambda x: data[(data['user_id'] == similar_users[0][0]) |\n",
    "                                                                 (data['user_id'] == similar_users[1][0])]['clicks'].sum(),\n",
    "                               reverse=True)\n",
    "        \n",
    "        recommended_movies.extend(common_movies[:min(5, len(common_movies))])\n",
    "    \n",
    "    # If no common movies, recommend most clicked movies by the most similar user first, then the other user\n",
    "    else:\n",
    "        most_clicked_by_similar = data[data['user_id'] == similar_users[0][0]].groupby('movie_id')['clicks'].sum()\n",
    "        most_clicked_by_other = data[data['user_id'] == similar_users[1][0]].groupby('movie_id')['clicks'].sum()\n",
    "        \n",
    "        # Sort by clicks in descending order\n",
    "        most_clicked_by_similar = most_clicked_by_similar.sort_values(ascending=False)\n",
    "        most_clicked_by_other = most_clicked_by_other.sort_values(ascending=False)\n",
    "        \n",
    "        # Get movie IDs from the sorted Series\n",
    "        most_clicked_by_similar = most_clicked_by_similar.index.tolist()\n",
    "        most_clicked_by_other = most_clicked_by_other.index.tolist()\n",
    "        \n",
    "        recommended_movies.extend(most_clicked_by_similar[:min(3, len(most_clicked_by_similar))])\n",
    "        recommended_movies.extend(most_clicked_by_other[:min(2, len(most_clicked_by_other))])\n",
    "    \n",
    "    return recommended_movies\n",
    "\n",
    "# Example: Recommend movies for a specific user\n",
    "user_id_to_recommend = '1dea19f6fe'  # Replace with the user ID for which you want to recommend movies\n",
    "recommended_movies = recommend_movies(user_id_to_recommend, minhashes, data)\n",
    "\n",
    "print(f\"Recommended movies for User {user_id_to_recommend}: {recommended_movies}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b58a9",
   "metadata": {},
   "source": [
    "## 2. Grouping Users together!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45294059",
   "metadata": {},
   "source": [
    "### 2.1 Getting your data + feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cdfaf4",
   "metadata": {},
   "source": [
    "Favorite genre :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d5400286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0             datetime  duration  \\\n",
      "0            58773  2017-01-01 01:15:09       0.0   \n",
      "1            58774  2017-01-01 13:56:02       0.0   \n",
      "2            58775  2017-01-01 15:17:47   10530.0   \n",
      "3            58776  2017-01-01 16:04:13      49.0   \n",
      "4            58777  2017-01-01 19:16:37       0.0   \n",
      "...            ...                  ...       ...   \n",
      "671731      730504  2019-06-30 21:37:08     851.0   \n",
      "671732      730505  2019-06-30 21:49:34   91157.0   \n",
      "671733      730506  2019-06-30 22:00:44       0.0   \n",
      "671734      730507  2019-06-30 22:04:23       0.0   \n",
      "671735      730508  2019-06-30 22:35:24       0.0   \n",
      "\n",
      "                                            title  \\\n",
      "0              Angus, Thongs and Perfect Snogging   \n",
      "1                    The Curse of Sleeping Beauty   \n",
      "2                               London Has Fallen   \n",
      "3                                        Vendetta   \n",
      "4                 The SpongeBob SquarePants Movie   \n",
      "...                                           ...   \n",
      "671731        Oprah Presents When They See Us Now   \n",
      "671732                               HALO Legends   \n",
      "671733                                Pacific Rim   \n",
      "671734  ReMastered: The Two Killings of Sam Cooke   \n",
      "671735                                 Chopsticks   \n",
      "\n",
      "                                                   genres release_date  \\\n",
      "0                                  Comedy, Drama, Romance   2008-07-25   \n",
      "1                      Fantasy, Horror, Mystery, Thriller   2016-06-02   \n",
      "2                                        Action, Thriller   2016-03-04   \n",
      "3                                           Action, Drama   2015-06-12   \n",
      "4       Animation, Action, Adventure, Comedy, Family, ...   2004-11-19   \n",
      "...                                                   ...          ...   \n",
      "671731                                          Talk-Show   2019-06-12   \n",
      "671732       Animation, Action, Adventure, Family, Sci-Fi   2010-02-16   \n",
      "671733                          Action, Adventure, Sci-Fi   2013-07-12   \n",
      "671734                                 Documentary, Music   2019-02-08   \n",
      "671735                                      Comedy, Drama   2019-05-31   \n",
      "\n",
      "          movie_id     user_id  clicks favorite genre  \n",
      "0       26bd5987e8  1dea19f6fe     840         Comedy  \n",
      "1       f26ed2675e  544dcbc510      75        Romance  \n",
      "2       f77e500e7a  7cbcc791bf    1084         Action  \n",
      "3       c74aec7673  ebf43c36b6      11         Action  \n",
      "4       a80d6fc2aa  a57c992287     637          Drama  \n",
      "...            ...         ...     ...            ...  \n",
      "671731  43cd23f30f  57501964fd      77      Talk-Show  \n",
      "671732  febf42d55f  d4fcb079ba     183         Action  \n",
      "671733  7b15e5ada1  4a14a2cd5a     355         Action  \n",
      "671734  52d49c515a  0b8163ea4b     104    Documentary  \n",
      "671735  0be62aac8b  5e5755d816      60          Drama  \n",
      "\n",
      "[671736 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from CSV file\n",
    "csv_file_path = 'vodclickstream_uk_movies_03_2.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Split genres into a list\n",
    "data['genres'] = data['genres'].str.split(',')\n",
    "\n",
    "# Duplicate rows based on the number of genres\n",
    "data_expanded = data.explode('genres')\n",
    "\n",
    "# Calculate the most frequently occurring genre for each user\n",
    "favorite_genre = data_expanded.groupby('user_id')['genres'].agg(lambda x: x.value_counts().idxmax()).reset_index()\n",
    "\n",
    "# Create a dictionary mapping user IDs to their favorite genres\n",
    "user_favorite_genres = dict(zip(favorite_genre['user_id'], favorite_genre['genres']))\n",
    "\n",
    "# Add a new column based on the key-value mapping\n",
    "data['favorite genre'] = data['user_id'].map(user_favorite_genres)\n",
    "\n",
    "# Reassemble genres as a single string\n",
    "data['genres'] = data['genres'].apply(','.join)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_csv_path = 'vodclickstream_uk_movies_03_3.csv'  \n",
    "data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "data = pd.read_csv(output_csv_path)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb61a55",
   "metadata": {},
   "source": [
    "Average duration click :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d9c6f32d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           user_id      duration\n",
      "0       00004e2862      0.000000\n",
      "1       000052a0a0   2024.166667\n",
      "2       000090e7c8      0.000000\n",
      "3       000118a755     -0.250000\n",
      "4       000296842d   9663.375000\n",
      "...            ...           ...\n",
      "161913  fffd9bf758   8495.000000\n",
      "161914  fffe7b777b   1785.000000\n",
      "161915  fffeac83be  40606.272727\n",
      "161916  ffff2c5f9e      0.000000\n",
      "161917  ffffd36adf      0.000000\n",
      "\n",
      "[161918 rows x 2 columns]\n",
      "        Unnamed: 0             datetime  duration  \\\n",
      "0            58773  2017-01-01 01:15:09       0.0   \n",
      "1            58774  2017-01-01 13:56:02       0.0   \n",
      "2            58775  2017-01-01 15:17:47   10530.0   \n",
      "3            58776  2017-01-01 16:04:13      49.0   \n",
      "4            58777  2017-01-01 19:16:37       0.0   \n",
      "...            ...                  ...       ...   \n",
      "671731      730504  2019-06-30 21:37:08     851.0   \n",
      "671732      730505  2019-06-30 21:49:34   91157.0   \n",
      "671733      730506  2019-06-30 22:00:44       0.0   \n",
      "671734      730507  2019-06-30 22:04:23       0.0   \n",
      "671735      730508  2019-06-30 22:35:24       0.0   \n",
      "\n",
      "                                            title  \\\n",
      "0              Angus, Thongs and Perfect Snogging   \n",
      "1                    The Curse of Sleeping Beauty   \n",
      "2                               London Has Fallen   \n",
      "3                                        Vendetta   \n",
      "4                 The SpongeBob SquarePants Movie   \n",
      "...                                           ...   \n",
      "671731        Oprah Presents When They See Us Now   \n",
      "671732                               HALO Legends   \n",
      "671733                                Pacific Rim   \n",
      "671734  ReMastered: The Two Killings of Sam Cooke   \n",
      "671735                                 Chopsticks   \n",
      "\n",
      "                                                   genres release_date  \\\n",
      "0                                  Comedy, Drama, Romance   2008-07-25   \n",
      "1                      Fantasy, Horror, Mystery, Thriller   2016-06-02   \n",
      "2                                        Action, Thriller   2016-03-04   \n",
      "3                                           Action, Drama   2015-06-12   \n",
      "4       Animation, Action, Adventure, Comedy, Family, ...   2004-11-19   \n",
      "...                                                   ...          ...   \n",
      "671731                                          Talk-Show   2019-06-12   \n",
      "671732       Animation, Action, Adventure, Family, Sci-Fi   2010-02-16   \n",
      "671733                          Action, Adventure, Sci-Fi   2013-07-12   \n",
      "671734                                 Documentary, Music   2019-02-08   \n",
      "671735                                      Comedy, Drama   2019-05-31   \n",
      "\n",
      "          movie_id     user_id  clicks favorite genre  average duration  \n",
      "0       26bd5987e8  1dea19f6fe     840         Comedy          0.000000  \n",
      "1       f26ed2675e  544dcbc510      75        Romance       1553.750000  \n",
      "2       f77e500e7a  7cbcc791bf    1084         Action       4218.666667  \n",
      "3       c74aec7673  ebf43c36b6      11         Action       1883.533333  \n",
      "4       a80d6fc2aa  a57c992287     637          Drama       3684.538462  \n",
      "...            ...         ...     ...            ...               ...  \n",
      "671731  43cd23f30f  57501964fd      77      Talk-Show        851.000000  \n",
      "671732  febf42d55f  d4fcb079ba     183         Action      22533.416667  \n",
      "671733  7b15e5ada1  4a14a2cd5a     355         Action        502.500000  \n",
      "671734  52d49c515a  0b8163ea4b     104    Documentary      15072.000000  \n",
      "671735  0be62aac8b  5e5755d816      60          Drama      42839.545455  \n",
      "\n",
      "[671736 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from CSV file\n",
    "csv_file_path = 'vodclickstream_uk_movies_03_3.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Calculate the average duration per user\n",
    "average_duration = data.groupby('user_id')['duration'].mean().reset_index()\n",
    "print(average_duration)\n",
    "\n",
    "# Add a new column based on the key-value mapping\n",
    "average_duration_per_user = dict(zip(average_duration['user_id'], average_duration['duration']))\n",
    "\n",
    "data['average duration'] = data['user_id'].map(average_duration_per_user)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_csv_path = 'vodclickstream_uk_movies_03_3.csv'  \n",
    "data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "data = pd.read_csv(output_csv_path)\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a1a36",
   "metadata": {},
   "source": [
    "Time of the day : \n",
    "- 6 - 14 h morning \n",
    "- 14 - 20 h afternoon \n",
    "- 20 - 6 h night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9930f5d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0            datetime  duration  \\\n",
      "0            58773 2017-01-01 01:15:09       0.0   \n",
      "1            58774 2017-01-01 13:56:02       0.0   \n",
      "2            58775 2017-01-01 15:17:47   10530.0   \n",
      "3            58776 2017-01-01 16:04:13      49.0   \n",
      "4            58777 2017-01-01 19:16:37       0.0   \n",
      "...            ...                 ...       ...   \n",
      "671731      730504 2019-06-30 21:37:08     851.0   \n",
      "671732      730505 2019-06-30 21:49:34   91157.0   \n",
      "671733      730506 2019-06-30 22:00:44       0.0   \n",
      "671734      730507 2019-06-30 22:04:23       0.0   \n",
      "671735      730508 2019-06-30 22:35:24       0.0   \n",
      "\n",
      "                                            title  \\\n",
      "0              Angus, Thongs and Perfect Snogging   \n",
      "1                    The Curse of Sleeping Beauty   \n",
      "2                               London Has Fallen   \n",
      "3                                        Vendetta   \n",
      "4                 The SpongeBob SquarePants Movie   \n",
      "...                                           ...   \n",
      "671731        Oprah Presents When They See Us Now   \n",
      "671732                               HALO Legends   \n",
      "671733                                Pacific Rim   \n",
      "671734  ReMastered: The Two Killings of Sam Cooke   \n",
      "671735                                 Chopsticks   \n",
      "\n",
      "                                                   genres release_date  \\\n",
      "0                                  Comedy, Drama, Romance   2008-07-25   \n",
      "1                      Fantasy, Horror, Mystery, Thriller   2016-06-02   \n",
      "2                                        Action, Thriller   2016-03-04   \n",
      "3                                           Action, Drama   2015-06-12   \n",
      "4       Animation, Action, Adventure, Comedy, Family, ...   2004-11-19   \n",
      "...                                                   ...          ...   \n",
      "671731                                          Talk-Show   2019-06-12   \n",
      "671732       Animation, Action, Adventure, Family, Sci-Fi   2010-02-16   \n",
      "671733                          Action, Adventure, Sci-Fi   2013-07-12   \n",
      "671734                                 Documentary, Music   2019-02-08   \n",
      "671735                                      Comedy, Drama   2019-05-31   \n",
      "\n",
      "          movie_id     user_id  clicks favorite genre  average duration  \\\n",
      "0       26bd5987e8  1dea19f6fe     840         Comedy          0.000000   \n",
      "1       f26ed2675e  544dcbc510      75        Romance       1553.750000   \n",
      "2       f77e500e7a  7cbcc791bf    1084         Action       4218.666667   \n",
      "3       c74aec7673  ebf43c36b6      11         Action       1883.533333   \n",
      "4       a80d6fc2aa  a57c992287     637          Drama       3684.538462   \n",
      "...            ...         ...     ...            ...               ...   \n",
      "671731  43cd23f30f  57501964fd      77      Talk-Show        851.000000   \n",
      "671732  febf42d55f  d4fcb079ba     183         Action      22533.416667   \n",
      "671733  7b15e5ada1  4a14a2cd5a     355         Action        502.500000   \n",
      "671734  52d49c515a  0b8163ea4b     104    Documentary      15072.000000   \n",
      "671735  0be62aac8b  5e5755d816      60          Drama      42839.545455   \n",
      "\n",
      "       time_category  \n",
      "0              Night  \n",
      "1          Afternoon  \n",
      "2          Afternoon  \n",
      "3          Afternoon  \n",
      "4          Afternoon  \n",
      "...              ...  \n",
      "671731         Night  \n",
      "671732         Night  \n",
      "671733         Night  \n",
      "671734         Night  \n",
      "671735         Night  \n",
      "\n",
      "[671736 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, time\n",
    "\n",
    "# Read data from CSV file\n",
    "csv_file_path = 'vodclickstream_uk_movies_03_3.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "def categorize_time(row):\n",
    "    # Extract only the time part\n",
    "    time_part = row['datetime'].time()\n",
    "\n",
    "    # Categorize the time\n",
    "    if time(6, 0, 0) <= time_part < time(13, 0, 0):\n",
    "        return 'Morning'\n",
    "    elif time(13, 0, 0) <= time_part < time(20, 0, 0):\n",
    "        return 'Afternoon'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "def timeframe():\n",
    "    # Convert 'datetime' column to datetime type\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "\n",
    "    # Create a new column 'time_category' based on the categorization function\n",
    "    data['time_category'] = data.apply(categorize_time, axis=1)\n",
    "\n",
    "    # Print the DataFrame with the new category\n",
    "    print(data)\n",
    "    output_csv_path = 'vodclickstream_uk_movies_03_3.csv'  \n",
    "    data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "timeframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a077618b",
   "metadata": {},
   "source": [
    "Movie preference :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "838d75ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0             datetime  duration  \\\n",
      "0            58773  2017-01-01 01:15:09       0.0   \n",
      "1            58774  2017-01-01 13:56:02       0.0   \n",
      "2            58775  2017-01-01 15:17:47   10530.0   \n",
      "3            58776  2017-01-01 16:04:13      49.0   \n",
      "4            58777  2017-01-01 19:16:37       0.0   \n",
      "...            ...                  ...       ...   \n",
      "671731      730504  2019-06-30 21:37:08     851.0   \n",
      "671732      730505  2019-06-30 21:49:34   91157.0   \n",
      "671733      730506  2019-06-30 22:00:44       0.0   \n",
      "671734      730507  2019-06-30 22:04:23       0.0   \n",
      "671735      730508  2019-06-30 22:35:24       0.0   \n",
      "\n",
      "                                            title  \\\n",
      "0              Angus, Thongs and Perfect Snogging   \n",
      "1                    The Curse of Sleeping Beauty   \n",
      "2                               London Has Fallen   \n",
      "3                                        Vendetta   \n",
      "4                 The SpongeBob SquarePants Movie   \n",
      "...                                           ...   \n",
      "671731        Oprah Presents When They See Us Now   \n",
      "671732                               HALO Legends   \n",
      "671733                                Pacific Rim   \n",
      "671734  ReMastered: The Two Killings of Sam Cooke   \n",
      "671735                                 Chopsticks   \n",
      "\n",
      "                                                   genres release_date  \\\n",
      "0                                  Comedy, Drama, Romance   2008-07-25   \n",
      "1                      Fantasy, Horror, Mystery, Thriller   2016-06-02   \n",
      "2                                        Action, Thriller   2016-03-04   \n",
      "3                                           Action, Drama   2015-06-12   \n",
      "4       Animation, Action, Adventure, Comedy, Family, ...   2004-11-19   \n",
      "...                                                   ...          ...   \n",
      "671731                                          Talk-Show   2019-06-12   \n",
      "671732       Animation, Action, Adventure, Family, Sci-Fi   2010-02-16   \n",
      "671733                          Action, Adventure, Sci-Fi   2013-07-12   \n",
      "671734                                 Documentary, Music   2019-02-08   \n",
      "671735                                      Comedy, Drama   2019-05-31   \n",
      "\n",
      "          movie_id     user_id  clicks favorite genre  average duration  \\\n",
      "0       26bd5987e8  1dea19f6fe     840         Comedy          0.000000   \n",
      "1       f26ed2675e  544dcbc510      75        Romance       1553.750000   \n",
      "2       f77e500e7a  7cbcc791bf    1084         Action       4218.666667   \n",
      "3       c74aec7673  ebf43c36b6      11         Action       1883.533333   \n",
      "4       a80d6fc2aa  a57c992287     637          Drama       3684.538462   \n",
      "...            ...         ...     ...            ...               ...   \n",
      "671731  43cd23f30f  57501964fd      77      Talk-Show        851.000000   \n",
      "671732  febf42d55f  d4fcb079ba     183         Action      22533.416667   \n",
      "671733  7b15e5ada1  4a14a2cd5a     355         Action        502.500000   \n",
      "671734  52d49c515a  0b8163ea4b     104    Documentary      15072.000000   \n",
      "671735  0be62aac8b  5e5755d816      60          Drama      42839.545455   \n",
      "\n",
      "       time_category    year movie_preference  \n",
      "0              Night  2008.0       old movies  \n",
      "1          Afternoon  2016.0    recent movies  \n",
      "2          Afternoon  2016.0    recent movies  \n",
      "3          Afternoon  2015.0    recent movies  \n",
      "4          Afternoon  2004.0       old movies  \n",
      "...              ...     ...              ...  \n",
      "671731         Night  2019.0    recent movies  \n",
      "671732         Night  2010.0       old movies  \n",
      "671733         Night  2013.0    recent movies  \n",
      "671734         Night  2019.0    recent movies  \n",
      "671735         Night  2019.0    recent movies  \n",
      "\n",
      "[671736 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read data from CSV file\n",
    "csv_file_path = 'vodclickstream_uk_movies_03_3.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Convert 'datetime' column to datetime type\n",
    "data['release_date'] = pd.to_datetime(data['release_date'], errors='coerce')\n",
    "\n",
    "# Extract only the year\n",
    "data['year'] = data['release_date'].dt.year\n",
    "\n",
    "# Use np.where to conditionally assign values\n",
    "data['movie_preference'] = np.where(data['year'] > 2010, 'recent movies', 'old movies')\n",
    "\n",
    "output_csv_path = 'vodclickstream_uk_movies_03_3.csv'  \n",
    "data.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Print the result\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bcb1ba",
   "metadata": {},
   "source": [
    "### 2.2 Choose your features (variables)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f6fbf4",
   "metadata": {},
   "source": [
    "Here are some reasons why normalization can be a good idea:\n",
    "\n",
    "Scale Sensitivity : Some machine learning algorithms, such as k-nearest neighbors or gradient descent-based optimization algorithms, are sensitive to the scale of features. Normalizing the features ensures that no single feature dominates the others.\n",
    "\n",
    "Convergence : Normalization can help algorithms converge faster during training. It can prevent large-scale features from overshadowing small-scale features, allowing the algorithm to make progress more consistently.\n",
    "\n",
    "Distance-Based Algorithms : Algorithms that rely on distances, such as k-means clustering or support vector machines, can benefit from normalization. It ensures that the distances between data points are calculated based on the relative importance of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ecd9db",
   "metadata": {},
   "source": [
    "Now, let's apply normalization and dimensionality reduction to your data. For demonstration purposes, I'll use the MinMaxScaler for normalization and Principal Component Analysis (PCA) for dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "313ac460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0             datetime  duration  \\\n",
      "0            58773  2017-01-01 01:15:09       0.0   \n",
      "1            58774  2017-01-01 13:56:02       0.0   \n",
      "2            58775  2017-01-01 15:17:47   10530.0   \n",
      "3            58776  2017-01-01 16:04:13      49.0   \n",
      "4            58777  2017-01-01 19:16:37       0.0   \n",
      "...            ...                  ...       ...   \n",
      "671731      730504  2019-06-30 21:37:08     851.0   \n",
      "671732      730505  2019-06-30 21:49:34   91157.0   \n",
      "671733      730506  2019-06-30 22:00:44       0.0   \n",
      "671734      730507  2019-06-30 22:04:23       0.0   \n",
      "671735      730508  2019-06-30 22:35:24       0.0   \n",
      "\n",
      "                                            title  \\\n",
      "0              Angus, Thongs and Perfect Snogging   \n",
      "1                    The Curse of Sleeping Beauty   \n",
      "2                               London Has Fallen   \n",
      "3                                        Vendetta   \n",
      "4                 The SpongeBob SquarePants Movie   \n",
      "...                                           ...   \n",
      "671731        Oprah Presents When They See Us Now   \n",
      "671732                               HALO Legends   \n",
      "671733                                Pacific Rim   \n",
      "671734  ReMastered: The Two Killings of Sam Cooke   \n",
      "671735                                 Chopsticks   \n",
      "\n",
      "                                                   genres release_date  \\\n",
      "0                                  Comedy, Drama, Romance   2008-07-25   \n",
      "1                      Fantasy, Horror, Mystery, Thriller   2016-06-02   \n",
      "2                                        Action, Thriller   2016-03-04   \n",
      "3                                           Action, Drama   2015-06-12   \n",
      "4       Animation, Action, Adventure, Comedy, Family, ...   2004-11-19   \n",
      "...                                                   ...          ...   \n",
      "671731                                          Talk-Show   2019-06-12   \n",
      "671732       Animation, Action, Adventure, Family, Sci-Fi   2010-02-16   \n",
      "671733                          Action, Adventure, Sci-Fi   2013-07-12   \n",
      "671734                                 Documentary, Music   2019-02-08   \n",
      "671735                                      Comedy, Drama   2019-05-31   \n",
      "\n",
      "          movie_id     user_id  clicks favorite genre  average duration  \\\n",
      "0       26bd5987e8  1dea19f6fe     840         Comedy          0.000000   \n",
      "1       f26ed2675e  544dcbc510      75        Romance       1553.750000   \n",
      "2       f77e500e7a  7cbcc791bf    1084         Action       4218.666667   \n",
      "3       c74aec7673  ebf43c36b6      11         Action       1883.533333   \n",
      "4       a80d6fc2aa  a57c992287     637          Drama       3684.538462   \n",
      "...            ...         ...     ...            ...               ...   \n",
      "671731  43cd23f30f  57501964fd      77      Talk-Show        851.000000   \n",
      "671732  febf42d55f  d4fcb079ba     183         Action      22533.416667   \n",
      "671733  7b15e5ada1  4a14a2cd5a     355         Action        502.500000   \n",
      "671734  52d49c515a  0b8163ea4b     104    Documentary      15072.000000   \n",
      "671735  0be62aac8b  5e5755d816      60          Drama      42839.545455   \n",
      "\n",
      "        time_category    year  movie_preference       PC1       PC2  \n",
      "0                   2  2008.0                 0  0.694837 -0.321292  \n",
      "1                   1  2016.0                 1 -0.316460  0.155444  \n",
      "2                   1  2016.0                 1 -0.316460  0.155444  \n",
      "3                   1  2015.0                 1 -0.316460  0.155444  \n",
      "4                   1  2004.0                 0  0.683272  0.178575  \n",
      "...               ...     ...               ...       ...       ...  \n",
      "671731              2  2019.0                 1 -0.304895 -0.344422  \n",
      "671732              2  2010.0                 0  0.694837 -0.321292  \n",
      "671733              2  2013.0                 1 -0.304895 -0.344422  \n",
      "671734              2  2019.0                 1 -0.304895 -0.344423  \n",
      "671735              2  2019.0                 1 -0.304896 -0.344423  \n",
      "\n",
      "[671736 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Read data from CSV file\n",
    "csv_file_path = 'vodclickstream_uk_movies_03_3.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Update some features to use them \n",
    "data['movie_preference'] = data['movie_preference'].replace({'old movies': 0, 'recent movies': 1})\n",
    "data['time_category'] = data['time_category'].replace({'Morning': 0, 'Afternoon': 1, 'Night': 2})\n",
    "\n",
    "# Extract features from dataframe\n",
    "feature_columns = ['movie_preference', 'time_category', 'average duration']\n",
    "X = data[feature_columns]\n",
    "\n",
    "# Normalize features using Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "n_components = 2  # Adjust the number of components as needed\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_normalized)\n",
    "\n",
    "# Create a new DataFrame with normalized and reduced features\n",
    "columns_pca = [f'PC{i+1}' for i in range(n_components)]\n",
    "data_normalized_pca = pd.DataFrame(X_pca, columns=columns_pca)\n",
    "\n",
    "# Concatenate the new DataFrame with the original data\n",
    "data = pd.concat([data, data_normalized_pca], axis=1)\n",
    "\n",
    "# Print the result\n",
    "print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
